{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lym11020/dacon_AI/blob/main/KLUE_RoBERTa_large.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUbYKuV101c0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_dlVTjt1EFd"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ta9cEpB0f0L"
      },
      "outputs": [],
      "source": [
        "# https://dacon.io/en/competitions/official/236037/overview/description\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "# for graphing\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNUfrjKV0gh0"
      },
      "outputs": [],
      "source": [
        "train_original = pd.read_csv('/content/drive/MyDrive/Dacon /data/train.csv')\n",
        "train_original.drop(columns=['ID'], inplace=True)\n",
        "test = pd.read_csv('/content/drive/MyDrive/Dacon /data/test.csv')\n",
        "test.drop(columns=['ID'], inplace=True)\n",
        "submission = pd.read_csv('/content/drive/MyDrive/Dacon /data/sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bx9uqa-85hdj"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def pre_process(texts):\n",
        "    pattern = r'\\([^)]*\\)'\n",
        "\n",
        "    for i in range(len(texts)):\n",
        "        texts[i] = re.sub(pattern=pattern, repl='', string = texts[i])\n",
        "        texts[i] = texts[i].replace('  ', ' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHE3RwSI9U1j"
      },
      "outputs": [],
      "source": [
        "pre_process(train_original['문장'])\n",
        "pre_process(test['문장'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sxwdBIt1GYL"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "CFG = {\n",
        "    'EPOCHS':15,\n",
        "    'LEARNING_RATE':1e-5,\n",
        "    'BATCH_SIZE':32,\n",
        "    'SEED':41\n",
        "}\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정\n",
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19XMp-8-1xVj"
      },
      "outputs": [],
      "source": [
        "train, val, _, _ = train_test_split(train_original, train_original['label'], test_size=0.03, random_state=CFG['SEED'])\n",
        "train = train.reset_index(drop=True)\n",
        "val = val.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKL7w_-B1yXa"
      },
      "outputs": [],
      "source": [
        "model_nm = 'klue/bert-base'\n",
        "base_model = AutoModel.from_pretrained(model_nm)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_nm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLR1lFUT1zXS"
      },
      "outputs": [],
      "source": [
        "tokenizer_len = [len(tokenizer(s)['input_ids']) for s in train['문장']]\n",
        "sns.histplot(tokenizer_len)\n",
        "plt.show()\n",
        "\n",
        "print(f'log value : {np.mean(tokenizer_len)+3*np.std(tokenizer_len)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKxVSFX410TS"
      },
      "outputs": [],
      "source": [
        "tokenizer_log = np.log(tokenizer_len)\n",
        "sns.histplot(tokenizer_log)\n",
        "plt.show()\n",
        "\n",
        "print(f'log value : {np.mean(tokenizer_log)+3*np.std(tokenizer_log)}')\n",
        "print(f'original value : {np.exp(np.mean(tokenizer_log)+3*np.std(tokenizer_log))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvdIoEPQ130U"
      },
      "outputs": [],
      "source": [
        "class SentenceTypeDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, labels=None):\n",
        "        texts = dataframe['문장'].values.tolist()\n",
        "\n",
        "        self.texts = [tokenizer(text, padding='max_length', max_length=134, truncation=True, return_tensors='pt') for text in texts]\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "\n",
        "        if self.labels is not None:\n",
        "            type_tmp = self.labels['type'][idx]\n",
        "            polarity_tmp = self.labels['polarity'][idx]\n",
        "            tense_tmp = self.labels['tense'][idx]\n",
        "            certainty_tmp = self.labels['certainty'][idx]\n",
        "            return text, torch.Tensor(type_tmp), torch.Tensor(polarity_tmp), torch.Tensor(tense_tmp), torch.Tensor(certainty_tmp)\n",
        "        else:\n",
        "            return text, torch.Tensor([-1,-1,-1,-1]), torch.Tensor([-1,-1,-1]), torch.Tensor([-1,-1,-1]), torch.Tensor([-1,-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21UKidC0149a"
      },
      "outputs": [],
      "source": [
        "class SentenceClassifier(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super().__init__()\n",
        "        self.klue = base_model # from transformers package\n",
        "\n",
        "        self.fc1 = nn.Linear(768, 32)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.type_clf = nn.Linear(32,4)\n",
        "        self.polarity_clf = nn.Linear(32,3)\n",
        "        self.tense_clf = nn.Linear(32,3)\n",
        "        self.certainty_clf = nn.Linear(32,2)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # input_ids : token's id / attention_mask : make a model to focus on which token\n",
        "        klue_out = self.klue(input_ids= input_ids, attention_mask = attention_mask)[0][:,0]\n",
        "\n",
        "        x = self.fc1(klue_out)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        type_output = self.type_clf(x)\n",
        "        type_output = self.softmax(type_output)\n",
        "        polarity_output = self.polarity_clf(x)\n",
        "        polarity_output = self.softmax(polarity_output)\n",
        "        tense_output = self.tense_clf(x)\n",
        "        tense_output = self.softmax(tense_output)\n",
        "        certainty_output = self.certainty_clf(x)\n",
        "        certainty_output = self.softmax(certainty_output)\n",
        "\n",
        "        return type_output, polarity_output, tense_output, certainty_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3rHx_Zc16QL"
      },
      "outputs": [],
      "source": [
        "def sentence_train(model, train_dataloader, val_dataloader, learning_rate, epochs, model_nm):\n",
        "    best_val_loss = 99999999999999 # setting max (act as infinity)\n",
        "    early_stopping_threshold_count = 0\n",
        "\n",
        "    criterion = {\n",
        "        'type' : nn.CrossEntropyLoss().to(device),\n",
        "        'polarity' : nn.CrossEntropyLoss().to(device),\n",
        "        'tense' : nn.CrossEntropyLoss().to(device),\n",
        "        'certainty' : nn.CrossEntropyLoss().to(device)\n",
        "    }\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    model = model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "\n",
        "        model.train() # sets into the training mode\n",
        "\n",
        "        for train_input, type_label, polarity_label, tense_label, certainty_label in tqdm(train_dataloader):\n",
        "            attention_mask = train_input['attention_mask'].to(device)\n",
        "            input_ids = train_input['input_ids'].squeeze(1).to(device)\n",
        "            type_label = type_label.to(device)\n",
        "            polarity_label = polarity_label.to(device)\n",
        "            tense_label = tense_label.to(device)\n",
        "            certainty_label = certainty_label.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            type_output, polarity_output, tense_output, certainty_output = model(input_ids, attention_mask) # from the forward function\n",
        "\n",
        "            loss = 0.25*criterion['type'](type_output, type_label.float()) + \\\n",
        "                   0.25*criterion['polarity'](polarity_output, polarity_label.float()) + \\\n",
        "                   0.25*criterion['tense'](tense_output, tense_label.float()) + \\\n",
        "                   0.25*criterion['certainty'](certainty_output, certainty_label.float())\n",
        "            total_loss_train += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "        with torch.no_grad(): # since we should not change gradient for validation\n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            model.eval() # deactivate training\n",
        "\n",
        "            # same process as the above\n",
        "            for val_input, vtype_label, vpolarity_label, vtense_label, vcertainty_label in tqdm(val_dataloader):\n",
        "                attention_mask = val_input['attention_mask'].to(device)\n",
        "                input_ids = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                vtype_label = vtype_label.to(device)\n",
        "                vpolarity_label = vpolarity_label.to(device)\n",
        "                vtense_label = vtense_label.to(device)\n",
        "                vcertainty_label = vcertainty_label.to(device)\n",
        "\n",
        "                vtype_output, vpolarity_output, vtense_output, vcertainty_output = model(input_ids, attention_mask) # from the forward function\n",
        "\n",
        "                loss = 0.25*criterion['type'](vtype_output, vtype_label.float()) + \\\n",
        "                        0.25*criterion['polarity'](vpolarity_output, vpolarity_label.float()) + \\\n",
        "                        0.25*criterion['tense'](vtense_output, vtense_label.float()) + \\\n",
        "                        0.25*criterion['certainty'](vcertainty_output, vcertainty_label.float())\n",
        "\n",
        "                total_loss_val += loss.item()\n",
        "\n",
        "\n",
        "            print(f'Epochs: {epoch + 1} '\n",
        "                  f'| Train Loss: {total_loss_train / len(train_dataloader): .3f} '\n",
        "                  f'| Train Accuracy: {total_acc_train / (len(train_dataloader.dataset)): .3f} '\n",
        "                  f'| Val Loss: {total_loss_val / len(val_dataloader): .3f} '\n",
        "                  f'| Val Accuracy: {total_acc_val / len(val_dataloader.dataset): .3f}')\n",
        "\n",
        "            if best_val_loss > total_loss_val:\n",
        "                best_val_loss = total_loss_val # saving only the best one\n",
        "                torch.save(model, f\"/content/drive/MyDrive/Dacon /model/{model_nm}.pt\")\n",
        "                print(\"Saved model\")\n",
        "                early_stopping_threshold_count = 0\n",
        "            else:\n",
        "                early_stopping_threshold_count += 1 # checking how many epochs have passed that val_loss didn't increase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTBXJaIB18bL"
      },
      "outputs": [],
      "source": [
        "train_tmp = train[['문장', '유형', '극성', '시제', '확실성']]\n",
        "train_tmp = pd.get_dummies(train_tmp, columns=['유형', '극성', '시제', '확실성'])\n",
        "train_tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzAUsrj619vK"
      },
      "outputs": [],
      "source": [
        "train_type = train_tmp.iloc[:,1:5].values.tolist()\n",
        "train_polarity = train_tmp.iloc[:,5:8].values.tolist()\n",
        "train_tense = train_tmp.iloc[:,8:11].values.tolist()\n",
        "train_certainty = train_tmp.iloc[:,11:13].values.tolist()\n",
        "train_labels = {\n",
        "    'type': train_type,\n",
        "    'polarity': train_polarity,\n",
        "    'tense': train_tense,\n",
        "    'certainty': train_certainty\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkeBEb1u1_Da"
      },
      "outputs": [],
      "source": [
        "val_tmp = val[['문장', '유형', '극성', '시제', '확실성']]\n",
        "val_tmp = pd.get_dummies(val_tmp, columns=['유형', '극성', '시제', '확실성'])\n",
        "\n",
        "val_type = val_tmp.iloc[:,1:5].values.tolist()\n",
        "val_polarity = val_tmp.iloc[:,5:8].values.tolist()\n",
        "val_tense = val_tmp.iloc[:,8:11].values.tolist()\n",
        "val_certainty = val_tmp.iloc[:,11:13].values.tolist()\n",
        "val_labels = {\n",
        "    'type': val_type,\n",
        "    'polarity': val_polarity,\n",
        "    'tense': val_tense,\n",
        "    'certainty': val_certainty\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSf9oF1D2AJL"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(SentenceTypeDataset(train_tmp, tokenizer, train_labels), batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0) # num_workers: how many subprocesses to use for data loading\n",
        "val_dataloader = DataLoader(SentenceTypeDataset(val_tmp, tokenizer, val_labels), batch_size=CFG['BATCH_SIZE'], num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxv2f7Mw2BPD"
      },
      "outputs": [],
      "source": [
        "model = SentenceClassifier(base_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVwyrPt8XMLr"
      },
      "outputs": [],
      "source": [
        "model_name = 'kluebert-base'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGjtvI7z2CW7"
      },
      "outputs": [],
      "source": [
        "sentence_train(model, train_dataloader, val_dataloader, CFG['LEARNING_RATE'], CFG['EPOCHS'], model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VauHurEB2DSM"
      },
      "outputs": [],
      "source": [
        "def get_type_predictions(model, loader):\n",
        "\n",
        "    device = torch.device('cuda')\n",
        "    model = model.to(device)\n",
        "\n",
        "    type_probs, polarity_probs, tense_probs, clarity_probs = [], [], [], []\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for data_input, _, _, _, _ in tqdm(loader):\n",
        "            attention_mask = data_input['attention_mask'].to(device)\n",
        "            input_ids = data_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "\n",
        "            type_output, polarity_output, tense_output, clarity_output = model(input_ids, attention_mask)\n",
        "            type_probs.append(type_output)\n",
        "            polarity_probs.append(polarity_output)\n",
        "            tense_probs.append(tense_output)\n",
        "            clarity_probs.append(clarity_output)\n",
        "\n",
        "    return torch.cat(type_probs).cpu().detach().numpy(), \\\n",
        "            torch.cat(polarity_probs).cpu().detach().numpy(), \\\n",
        "            torch.cat(tense_probs).cpu().detach().numpy(), \\\n",
        "            torch.cat(clarity_probs).cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFG-2gH_3X6b"
      },
      "outputs": [],
      "source": [
        "#model = torch.load(\"/content/drive/MyDrive/kclue.pt/\"+model_name+'.pt')\n",
        "test_dataloader = DataLoader(SentenceTypeDataset(test, tokenizer), batch_size=CFG['BATCH_SIZE'], shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6eN7Pm_3cSb"
      },
      "outputs": [],
      "source": [
        "test_pred_type, test_pred_polarity, test_pred_tense, test_pred_certainty = get_type_predictions(model, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsuyzQhJ3cfS"
      },
      "outputs": [],
      "source": [
        "test_type = ['대화형' if i==0 else '사실형' if i==1 else '예측형' if i==2 else '추론형' for i in [np.argmax(p) for p in test_pred_type]]\n",
        "test_polarity = ['긍정' if i==0 else '미정' if i==1 else '부정' for i in [np.argmax(p) for p in test_pred_polarity]]\n",
        "test_tense = ['과거' if i==0 else '미래' if i==1 else '현재' for i in [np.argmax(p) for p in test_pred_tense]]\n",
        "test_certainty = ['불확실' if i==0 else '확실' for i in [np.argmax(p) for p in test_pred_certainty]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvMzzA5w3e_y"
      },
      "outputs": [],
      "source": [
        "label_sum = []\n",
        "for i in range(len(test_type)):\n",
        "    label_sum.append(f'{test_type[i]}-{test_polarity[i]}-{test_tense[i]}-{test_certainty[i]}')\n",
        "\n",
        "submission['label'] = label_sum\n",
        "submission.to_csv('/content/drive/MyDrive/kluebert.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1Kjvmyf99pR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}